1.mvNCCompile
/usr/local/bin/mvNCCompile -> /usr/local/bin/ncsdk/mvNCCompile.py*

2.mvNCCompile.py:
	filetype = network.split(".")[-1]
    if filetype in ["prototxt"]:
        from Controllers.CaffeParser import parse_caffe
        net = parse_caffe(args, myriad_config)
    elif filetype in ["pb", "protobuf", "meta"]:
        from Controllers.TensorFlowParser import parse_tensor
        net = parse_tensor(args, myriad_config)
    else:
        throw_error(ErrorTable.ParserNotSupported)

3.parse caffe:(CaffeParser.py)
	try:
    		os.environ['GLOG_minloglevel'] = '2'  # Supress Caffe Output
    		import caffe
	except ImportError:
    		print("Error importing caffe")
   		quit()

	try:
    		from caffe.proto import caffe_pb2
	except ImportError:
    		print("Error importing caffe module caffe_pb2")
    		quit()


	
	def parse_caffe(arguments, myriad_conf, debug=False, file_gen=False):
	...
	...
    	caffe.set_mode_cpu()
    	description = path
    	if weights is None:
        	open("zero_weights.caffemodel", "wb").close()
        	weights = "zero_weights.caffemodel"
        	print("\033[91m****** WARNING: using empty weights ******\033[0m")
    	if not os.path.isfile(weights):
        	throw_error(ErrorTable.ArgumentErrorWeights)
   	 try:
        	net = caffe.Net(description, weights, caffe.TEST)
    	except MemoryError:
        	throw_error(ErrorTable.CaffeMemoryError)
    	try:
        	f = open(description)
        	file_contents = f.read()
        	f.close()
    	except BaseException:
        	throw_error(ErrorTable.ArgumentErrorDescription)
    	msg = caffe_pb2.NetParameter()  # Parse via Caffe's NetParameter
    	text_format.Merge(str(file_contents), msg)


	for idx, layer in enumerate(layers):
		if isEltwise(layer.type) ...

		
		if isEltwise(layer.type) or isConcat(layer.type):

		if isDropout(layer.type):
            		continue
        	if isBatchNorm(layer.type) or isScale(layer.type):
			

		if isInnerLRN(layer):


		if isPriorBox(layer.type):

		if isReshape(layer.type):
            		if(len(layer.reshape_param.shape.dim) == 3):
                		new_shape_X = 1
                		new_shape_Y = layer.reshape_param.shape.dim[2]
                		new_shape_C = layer.reshape_param.shape.dim[1]
            		else:
                		new_shape_X = layer.reshape_param.shape.dim[3]
                		new_shape_Y = layer.reshape_param.shape.dim[2]
                		new_shape_C = layer.reshape_param.shape.dim[1]

           		network.attach(
                		NetworkStage(layer.name,
                             		top,
                             		StorageOrder.orderZYX,
                             		0,
                             		0,
                             		PadStyle.caffe,
                             		DataType.fp16,
                             		DataType.fp16,
                             		StageType.reshape,
                             		# Radix and stride
                             		1,
                             		1,
                             		1,
                             		1,
                             		# X, Y, Z
                             		inshape[2],
                             		inshape[1],
                             		inshape[0],
                             		# fh, fw
                             		1,
                             		1,
                             		# Output Channels (K)
                             		inshape[0],
                             		# Taps, Bias,
                             		None,
                             		TapsOrder.orderKCHW,
                             		None,
                             		# Pre and post ops
                             		None,
                             		StageType.none,
                             		None,
                             		0,
                             		0,
                             		None,
                             		myriad_conf,
                             		arguments,
                             		new_x = new_shape_X,
                             		new_y = new_shape_Y,
                             		new_c = new_shape_C)
            		)
            		last_layer = layer
            		if layer.name == outputNodeName:
                		break
            		continue
		if isPriorBox(layer.type):
			params=.......
			params=.......
			node = NetworkStage(......)
			network.attach(node)

            		last_layer = layer
            		if layer.name == outputNodeName:
                		break
           		continue
		if (isDetectionOutput(layer.type)):
			if (isPower(layer.type) or 
           			isNormalize(layer.type) or 
          			isPermute(layer.type)):
					params=.......
					params=.......
					node = NetworkStage(......)
					network.attach(node)

            				last_layer = layer
            				if layer.name == outputNodeName:
                				break
           				continue

		if isSoftMax(layer.type):


		if isCrop(layer.type):

		
		if arguments.explicit_concat and isConcat(layer.type):


		if isDepthwiseConvolution(layer, get_caffe_output_channels(
                	layer, inshape, top, network), inshape[0]):
			

		if (
            		not isReLU(layer.type) and not
            		isConcat(layer.type) and not
            		isSlice(layer.type) and not
            		isELU(layer.type) and not
            		isDepthwiseConvolution(
                		layer,
                		get_caffe_output_channels(
                   		layer,
                    		inshape,
                    		top,
                    		network),
                		inshape[0])):

            		layer_params = None
            		if(isConvolution(layer.type) or isDeconvolution(layer.type)):


		else:
            		caffe_apply_minor_op(network, layer, top)
        		last_layer = layer
        		if layer.name == outputNodeName:
            			break
	
	if last_layer.type == 'Concat':
        	nodes = network.search_several(last_layer.bottom)
        	NetworkStage.concat(nodes)

    	if(isDetectionOutput(last_layer.type)):
        	network.outputIsSsdDetOut = True

    	if outputNodeName is not None:
        	if inputNodeName is not None:
            	# Ensure we have the same inputs for each method
            		net.blobs[input_bottom].data[...] = input_data
            		try:
                		net.forward(start=startNodeName, end=outputNodeName)
           		except BaseException:
                		throw_error(ErrorTable.NoOutputNode,
                            		outputNodeName + "/" + startNodeName)
        	else:
            		# Ensure we have the same inputs for each method
           		 net.blobs['data'].data[...] = input_data
            		try:
                		net.forward(end=outputNodeName)
            		except BaseException:
                		throw_error(ErrorTable.NoOutputNode, outputNodeName)
   	else:
        	if inputNodeName is not None:
            	# Ensure we have the same inputs for each method
            		net.blobs[input_bottom].data[...] = input_data
            		net.forward(start=startNodeName)
        	else:
            	# Ensure we have the same inputs for each method
            		net.blobs['data'].data[...] = input_data
            		net.forward()

    	if file_gen:
        	try:
            		np.save(filename + "_expected.npy",
                    		net.blobs[outputNodeName].data[0].astype(dtype=np.float16))

        	except BaseException:
            		throw_error(ErrorTable.NoOutputNode, extra=net.blobs.keys())

    caffe_output_shape = net.blobs[outputNodeName].data.shape
    output_shape       = np.ones(3, dtype = "i4")
    # Substract 1 because caffe output will (almost)always have the batch dimension.
    output_shape_len   = len(caffe_output_shape) - 1
    output_shape[0 : output_shape_len] = caffe_output_shape[1:]
    network.outputTensor = zyx_to_yxz_dimension_only(output_shape)

    return network


4.create graph:
def create_graph(network, inputnode = None, outputnode = None, outfile = 'graph', 
		nshaves = 1, inputsize = None, weights = None):
	

